<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
  <head>
    <title>rladies-ml.utf8.md</title>
    <meta charset="utf-8" />
    <link href="libs/remark-css-0.0.1/default.css" rel="stylesheet" />
    <link href="libs/remark-css-0.0.1/rladies-fonts.css" rel="stylesheet" />
    <link rel="stylesheet" href="resources/css/progress.css" type="text/css" />
    <link rel="stylesheet" href="resources/css/adds.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">




class: inverse, left, middle

background-image: url(resources/images/cover.gif)
background-size: cover

# Machine Learning

### com aplicações em R

&lt;img src="resources/images/logo-rladies.svg" width="150px"/&gt;
&lt;img src="resources/images/logo-ibm.png" width="150px"/&gt;

.large[Thiago Pires | R-Ladies | 31 Out 2019]

---
layout: true

background-image: url(resources/images/logo-rladies.svg)
background-position: 97% 3%
background-size: 7%

---
class: left middle
background-color: #00b33c

# Aprendizagem supervisionada

.large[Árvore e Floresta aleatória]

---
# Titanic


```r
require(titanic)
require(dplyr)

titanic_train %&gt;% glimpse()
```

```
## Observations: 891
## Variables: 12
## $ PassengerId &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 1…
## $ Survived    &lt;int&gt; 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1…
## $ Pclass      &lt;int&gt; 3, 1, 3, 1, 3, 3, 1, 3, 3, 2, 3, 1, 3, 3, 3, 2, 3, 2…
## $ Name        &lt;chr&gt; "Braund, Mr. Owen Harris", "Cumings, Mrs. John Bradl…
## $ Sex         &lt;chr&gt; "male", "female", "female", "female", "male", "male"…
## $ Age         &lt;dbl&gt; 22, 38, 26, 35, 35, NA, 54, 2, 27, 14, 4, 58, 20, 39…
## $ SibSp       &lt;int&gt; 1, 1, 0, 1, 0, 0, 0, 3, 0, 1, 1, 0, 0, 1, 0, 0, 4, 0…
## $ Parch       &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 1, 0, 0, 5, 0, 0, 1, 0…
## $ Ticket      &lt;chr&gt; "A/5 21171", "PC 17599", "STON/O2. 3101282", "113803…
## $ Fare        &lt;dbl&gt; 7.2500, 71.2833, 7.9250, 53.1000, 8.0500, 8.4583, 51…
## $ Cabin       &lt;chr&gt; "", "C85", "", "C123", "", "", "E46", "", "", "", "G…
## $ Embarked    &lt;chr&gt; "S", "C", "S", "S", "S", "Q", "S", "S", "S", "C", "S…
```

---
# Manipulação


```r
(train &lt;- 
  titanic_train %&gt;% 
  select(Survived, Pclass, Sex, Age) %&gt;%
  mutate(Survived = factor(x = Survived, labels = c("no", "yes")),
*        Pclass = factor(x = Pclass, labels = c("1st", "2nd", "3rd")),
         Sex = factor(x = Sex)) %&gt;% 
  as_tibble())
```

```
## # A tibble: 891 x 4
##    Survived Pclass Sex      Age
##    &lt;fct&gt;    &lt;fct&gt;  &lt;fct&gt;  &lt;dbl&gt;
##  1 no       3rd    male      22
##  2 yes      1st    female    38
##  3 yes      3rd    female    26
##  4 yes      1st    female    35
##  5 no       3rd    male      35
##  6 no       3rd    male      NA
##  7 no       1st    male      54
##  8 no       3rd    male       2
##  9 yes      3rd    female    27
## 10 yes      2nd    female    14
## # … with 881 more rows
```

---
# Sex `\(\times\)` Survived

.pull-left[

```r
require(ggplot2)

train %&gt;% 
  ggplot() +
  aes(Sex, ..count.., fill = Survived) + 
* geom_bar(position = "fill") +
  scale_y_continuous(
    labels = scales::percent_format(suffix = "")) +
  scale_fill_brewer(
    palette = "Accent", direction = -1) +
  labs(y = "%") +
  theme_minimal()
```
]

.pull-right[
&lt;img src="rladies-ml_files/figure-html/unnamed-chunk-3-1.png" width="504" /&gt;
]

---
# Pclass `\(\times\)` Survived

.pull-left[

```r
train %&gt;% 
  ggplot() +
  aes(Pclass, ..count.., fill = Survived) + 
  geom_bar(position = "fill") +
  scale_y_continuous(
    labels = scales::percent_format(suffix = "")) +
  scale_fill_brewer(
    palette = "Accent", direction = -1) +
  labs(y = "%") +
  theme_minimal()
```
]

.pull-right[
&lt;img src="rladies-ml_files/figure-html/unnamed-chunk-4-1.png" width="504" /&gt;
]

---
# Pclass `\(\times\)` Sex `\(\times\)` Survived

.pull-left[

```r
train %&gt;% 
  ggplot() +
  aes(Sex, ..count.., fill = Survived) + 
  geom_bar(position = "fill") +
  scale_y_continuous(
    labels = scales::percent_format(suffix = "")) +
  scale_fill_brewer(
    palette = "Accent", direction = -1) +
  labs(y = "%") +
* facet_grid(. ~ Pclass) +
  theme_minimal()
```
]

.pull-right[
&lt;img src="rladies-ml_files/figure-html/unnamed-chunk-5-1.png" width="504" /&gt;
]

---
# Age `\(\times\)` Survived

.pull-left[

```r
train %&gt;% 
  ggplot() +
  aes(Survived, Age, fill = Survived) +
* geom_boxplot() +
  scale_fill_brewer(
    palette = "Accent", direction = -1) +
  theme_minimal()
```
]

.pull-right[
&lt;img src="rladies-ml_files/figure-html/unnamed-chunk-6-1.png" width="504" /&gt;
]

---
# Árvore de decisão ([`rpart::`](https://cran.r-project.org/web/packages/rpart/vignettes/longintro.pdf))


```r
require(rpart)

cart0 &lt;- 
  train %&gt;% 
  rpart(Survived ~ Sex + Pclass + Age, 
        data = .,
        parms=list(split="gini")) # "gini" (default)/"information"

# summary(cart0) fornece informações sobre o ajuste
```

No `rpart` (Recursive PARTitioning) é implementada muitas das ideias contidas no CART (Classification and Regression Trees).

Por padrão, é usada a **medida Gini (G)** a fim de selecionar as divisões ao executar a classificação.

`$$G = \sum_{k = 1}^K \hat p_{mk} (1 - \hat p_{mk})$$`

.tiny[
- `\(K\)`: classes
- `\(m\)`: região
- `\(\hat p\)`: proporção na m-ésima região e k-ésima classe
]

&gt;Uma impureza Gini de 0 significa uma precisão de 100% na previsão da classe dos elementos.

---
# Árvore de decisão (`rpart.plot::`)

.pull-left[

```r
require(rpart.plot)

rpart.plot(cart0)
```
]

.pull-right[
&lt;img src="rladies-ml_files/figure-html/unnamed-chunk-8-1.png" width="504" /&gt;
]

---
# Interpretação do resultados

.pull-left[
&lt;img src="rladies-ml_files/figure-html/unnamed-chunk-9-1.png" width="504" /&gt;
]

.pull-right[

- No topo mostra 38% são sobreviventes de **100% dos passageiros**
- A primeira variável que discrimina quem sobreviveu ou não foi **sexo**
- No ramo esquerdo dos 65% homens, 19% sobreviveram
- Por outro lado de 35% das mulheres, 74% sobreviveram
- Homens maiores que 6 anos e meio (62% dos passageiros), 17% sobreviveram
- Homens menores que 6 anos e meio (3% dos passageiros), 67% sobreviveram
- Mulheres da `\(1^a\)` e `\(2^a\)` classe (19% dos passageiros), 95% sobreviveram
- Mulheres da `\(3^a\)` classe (16% dos passageiros), 50% sobreviveram

]

---
# Complexity Parameter (CP)

O parâmetro de complexidade `\(cp\)` é usado para controlar o tamanho da árvore de decisão e assim selecionar o tamanho ideal.

&gt;Contudo, se o custo de adicionar outra variável à árvore de decisão do nó atual estiver acima do valor de `\(cp\)`, a construção da árvore não continuará. O *default* é 0,01.


```r
cart0 %&gt;% printcp()
```

```
## 
## Classification tree:
## rpart(formula = Survived ~ Sex + Pclass + Age, data = ., parms = list(split = "gini"))
## 
## Variables actually used in tree construction:
## [1] Age    Pclass Sex   
## 
## Root node error: 342/891 = 0.38384
## 
## n= 891 
## 
##         CP nsplit rel error  xerror     xstd
## 1 0.444444      0   1.00000 1.00000 0.042446
## 2 0.023392      1   0.55556 0.55556 0.035750
## 3 0.014620      2   0.53216 0.56140 0.035886
## 4 0.011696      4   0.50292 0.54971 0.035612
## 5 0.010000      6   0.47953 0.50877 0.034599
```

---
# Complexity Parameter (CP)

.pull-left[
Alterando o `\(cp\)`.


```r
cart0 %&gt;% prune(cp = .02) %&gt;% rpart.plot()
```

&lt;img src="rladies-ml_files/figure-html/unnamed-chunk-11-1.png" width="504" /&gt;
]

.pull-right[

- Valores muito pequenos do `\(cp\)` aumentam a complexidade da árvore e poderá incorrer em *overfitting*.

- Valores altos podem produzir modelos mais simples e gerar *underfitting*.

&gt;*Muitos dos modelos no contexto do ML se utilizam de alguma parâmetros para lidar com a **regularidade (apertar ou afroxar o parafuso)***

.right[

.large[Então como avaliar estes parâmetros?]

.large[Outro ponto é: como estimar a habilidade do modelo em novos dados?]

]

]

---
# Cross-validation (`caret::`)

As reamostragens são feitas segundo cada parâmetro.


```r
require(caret)

set.seed(945)

cart1 &lt;- 
  train %&gt;% 
* filter_all(function(x) !is.na(x)) %&gt;%
  train(Survived ~ ., 
        data = ., 
        method="rpart", 
        trControl = trainControl(method = "cv", # cross-validation
                                 number = 7), # 7 folders
*       tuneLength = 5) # tuning cp

cart1$results
```

```
##            cp  Accuracy     Kappa AccuracySD    KappaSD
## 1 0.008045977 0.7969483 0.5619914 0.02481420 0.05795809
## 2 0.010344828 0.7927050 0.5552075 0.02437072 0.05620085
## 3 0.012068966 0.7927188 0.5500504 0.02065759 0.04414883
## 4 0.027586207 0.7689221 0.5035569 0.02351656 0.04993739
## 5 0.458620690 0.6412441 0.1415590 0.08225673 0.24222222
```

---
# Cross-validation (`caret::`)


```r
set.seed(945)

cart2 &lt;- 
  train %&gt;% 
  filter_all(function(x) !is.na(x)) %&gt;% 
  train(Survived ~ ., 
        data = ., 
        method="rpart", 
        trControl = trainControl(method = "cv", # cross-validation
                                 number = 7), # 7 folders
*       tuneGrid = expand.grid(cp = c(.04, .03, .02, .01, .00))) # tuning cp

cart2$results
```

```
##     cp  Accuracy     Kappa AccuracySD    KappaSD
## 1 0.00 0.8012331 0.5845530 0.03535142 0.06915786
## 2 0.01 0.7969483 0.5625457 0.02481420 0.05742078
## 3 0.02 0.7885308 0.5328726 0.02910832 0.06462175
## 4 0.03 0.7703229 0.5100354 0.01544380 0.04278896
## 5 0.04 0.7745523 0.5207047 0.01400591 0.03580337
```

---
# `rattle::fancyRpartPlot`

.pull-left[

```r
rattle::fancyRpartPlot(cart1$finalModel, sub = "")
```
]

.pull-right[
&lt;img src="rladies-ml_files/figure-html/unnamed-chunk-14-1.png" width="504" /&gt;
]

---
# Inserindo outras variáveis


```r
(train2 &lt;- 
  titanic_train %&gt;% 
  select(Survived, Pclass, Sex, Age, Fare, Embarked, SibSp) %&gt;%
  mutate(Survived = factor(x = Survived, labels = c("no", "yes")),
         Pclass = factor(x = Pclass, labels = c("1st", "2nd", "3rd")),
         Sex = factor(x = Sex),
         Embarked = factor(x = Embarked)) %&gt;% 
  as_tibble())
```

```
## # A tibble: 891 x 7
##    Survived Pclass Sex      Age  Fare Embarked SibSp
##    &lt;fct&gt;    &lt;fct&gt;  &lt;fct&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt;    &lt;int&gt;
##  1 no       3rd    male      22  7.25 S            1
##  2 yes      1st    female    38 71.3  C            1
##  3 yes      3rd    female    26  7.92 S            0
##  4 yes      1st    female    35 53.1  S            1
##  5 no       3rd    male      35  8.05 S            0
##  6 no       3rd    male      NA  8.46 Q            0
##  7 no       1st    male      54 51.9  S            0
##  8 no       3rd    male       2 21.1  S            3
##  9 yes      3rd    female    27 11.1  S            0
## 10 yes      2nd    female    14 30.1  C            1
## # … with 881 more rows
```

---
# `randomForest::`


```r
require(randomForest)

set.seed(2355)

rf0 &lt;- 
  train2 %&gt;% 
  filter_all(function(x) ! is.na(x)) %&gt;%
  randomForest(Survived ~ ., data = .,
               ntree = 500, # número de árvores
               mtry = 3, # número de variáveis de entrada escolhidas aleatoriamente
               nodesize = .01 * nrow(train2)) # define de forma implícita a profundidade
```

---
# `$importance` e `$confusion`

.pull-left[


```r
rf0$importance
```

```
##          MeanDecreaseGini
## Pclass          33.438440
*## Sex             90.610332
*## Age             56.267047
*## Fare            54.581048
## Embarked         6.194039
## SibSp           11.553208
```

&gt;Avaliar a **diminuição no GINI** quando essa variável é omitida leva a uma compreensão de quão importante é essa característica para dividir os dados corretamente.

]

.pull-right[


```r
rf0$confusion
```

```
##      no yes class.error
## no  379  45   0.1061321
## yes  85 205   0.2931034
```

```r
# 1 - class.error "no" (especificidade)
1 - 45/(45 + 379)
```

```
## [1] 0.8938679
```

```r
# 1 - class.error "yes" (sensibilidade)
1 - 85/(85 + 205)
```

```
## [1] 0.7068966
```

]

---
# Cross-validation (`caret::`)


```r
set.seed(1124)

rf1 &lt;- 
  train2 %&gt;% 
* filter_all(function(x) !is.na(x)) %&gt;%
  train(Survived ~ ., 
        data = ., 
        method="rf", 
        trControl = trainControl(method = "cv", # cross-validation
                                 number = 7), # 7 folders
        tuneLength = 5) #&lt;&lt; tuning mtry

rf1$results
```

```
##   mtry  Accuracy     Kappa AccuracySD    KappaSD
## 1    2 0.8067655 0.5801386 0.04113205 0.09451893
## 2    3 0.8136864 0.6023352 0.03647400 0.07917013
*## 3    5 0.8207034 0.6198681 0.03397160 0.07734250
## 4    7 0.8095666 0.5994598 0.04001580 0.08862467
## 5    9 0.8025633 0.5843355 0.04179134 0.09352189
```

---

# `$importance` e `$confusion`

.pull-left[

```r
rf1$finalModel$importance
```

```
##           MeanDecreaseGini
## Pclass2nd         6.468210
## Pclass3rd        27.141607
*## Sexmale          93.227922
*## Age              82.927530
*## Fare             79.261577
## EmbarkedC         4.692613
## EmbarkedQ         1.373727
## EmbarkedS         3.438334
## SibSp            14.853817
```
]

.pull-right[

```r
rf1$finalModel$confusion
```

```
##      no yes class.error
## no  373  51    0.120283
## yes  76 214    0.262069
```

```r
# 1 - class.error "no" (especificidade)
1 - 51/(51 + 373)
```

```
## [1] 0.879717
```

```r
# 1 - class.error "yes" (sensibilidade)
1 - 76/(76 + 214)
```

```
## [1] 0.737931
```
]

---
# Tuning multiplos parâmetros através de um *custom model*


```r
customRF &lt;- list(type = "Classification", library = "randomForest", loop = NULL)
customRF$parameters &lt;- data.frame(parameter = c("mtry", "ntree"), class = rep("numeric", 2), label = c("mtry", "ntree"))
customRF$grid &lt;- function(x, y, len = NULL, search = "grid") {}
customRF$fit &lt;- function(x, y, wts, param, lev, last, weights, classProbs, ...) {
  randomForest(x, y, mtry = param$mtry, ntree=param$ntree, ...)
}
customRF$predict &lt;- function(modelFit, newdata, preProc = NULL, submodels = NULL)
   predict(modelFit, newdata)
customRF$prob &lt;- function(modelFit, newdata, preProc = NULL, submodels = NULL)
   predict(modelFit, newdata, type = "prob")
customRF$sort &lt;- function(x) x[order(x[,1]),]
customRF$levels &lt;- function(x) x$classes
```

---
# Tuning multiplos parâmetros através de um *custom model*


```r
set.seed(1124)

grid &lt;- expand.grid(mtry = 2:5, ntree = c(100, 500, 900))
control &lt;- trainControl(method = "cv", number = 7)

rf2 &lt;- 
  train2 %&gt;% 
* filter_all(function(x) !is.na(x)) %&gt;%
  train(Survived ~ ., 
        data = ., 
*       method = customRF,
        trControl = control, tuneGrid = grid)
```

---
# Tuning multiplos parâmetros através de um *custom model*


```r
rf2$results
```

```
##    mtry ntree  Accuracy     Kappa AccuracySD    KappaSD
## 1     2   100 0.8096082 0.5865824 0.03811011 0.08847582
## 2     2   500 0.8053649 0.5772552 0.03735932 0.08443157
## 3     2   900 0.8025638 0.5708858 0.03943292 0.09031869
*## 4     3   100 0.8263334 0.6287908 0.04021150 0.08620839
## 5     3   500 0.8179433 0.6112418 0.03559338 0.07727648
## 6     3   900 0.8179705 0.6116625 0.04082195 0.08831873
## 7     4   100 0.8207586 0.6198022 0.03208986 0.06916259
## 8     4   500 0.8207583 0.6192364 0.03718136 0.08050013
## 9     4   900 0.8207719 0.6187691 0.03876836 0.08424504
## 10    5   100 0.8193300 0.6169804 0.03700729 0.08239342
## 11    5   500 0.8221314 0.6240543 0.03362464 0.07595688
## 12    5   900 0.8207037 0.6208801 0.02886859 0.06608060
```

---
class: left middle
background-color: #d1b3ff

# Aprendizagem não supervisionada

.large[Clusters: Hierárquico e Kmeans]

---
# Países


```r
require(readxl)

countries &lt;- read_xlsx("data/countries.xlsx")

countries %&gt;% glimpse
```

```
## Observations: 227
## Variables: 11
## $ Country                              &lt;chr&gt; "Afghanistan", "Albania", "…
## $ Region                               &lt;chr&gt; "ASIA (EX. NEAR EAST)", "EA…
## $ `Infant mortality (per 1000 births)` &lt;dbl&gt; 163.07, 21.52, 31.00, 9.27,…
## $ `GDP ($ per capita)`                 &lt;dbl&gt; 700, 4500, 6000, 8000, 1900…
## $ `Literacy (%)`                       &lt;dbl&gt; 36.0, 86.5, 70.0, 97.0, 100…
## $ `Phones (per 1000)`                  &lt;dbl&gt; 3.2, 71.2, 78.1, 259.5, 497…
## $ Birthrate                            &lt;dbl&gt; 46.60, 15.11, 17.14, 22.46,…
## $ Deathrate                            &lt;dbl&gt; 20.34, 5.22, 4.61, 3.27, 6.…
## $ Agriculture                          &lt;dbl&gt; 0.380, 0.232, 0.101, NA, NA…
## $ Industry                             &lt;dbl&gt; 0.240, 0.188, 0.600, NA, NA…
## $ Service                              &lt;dbl&gt; 0.380, 0.579, 0.298, NA, NA…
```

---
# Cluster hierárquico


```r
dataset &lt;-
  countries %&gt;% 
  group_by(Region) %&gt;%
  summarise_at(vars(`Infant mortality (per 1000 births)`:Service), 
               list(function(x) mean(x, na.rm = TRUE)))

names(dataset) &lt;- glue::glue("X{0:9}")

dataset
```

```
## # A tibble: 11 x 10
##    X0                  X1     X2    X3    X4    X5    X6     X7    X8    X9
##    &lt;chr&gt;            &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
##  1 ASIA (EX. NEAR … 41.8   8054.  79.6 171.  21.2   7.64 0.178  0.302 0.520
##  2 BALTICS           8.10 11300   99.7 293.   9.34 12.6  0.045  0.293 0.662
##  3 C.W. OF IND. ST… 44.4   4000   98.7 164.  17.9  10.3  0.192  0.328 0.480
##  4 EASTERN EUROPE   12.7   9808.  97.1 281.  10.4  10.3  0.0922 0.309 0.599
##  5 LATIN AMER. &amp; C… 20.1   8682.  90.7 272.  19.1   6.38 0.0910 0.256 0.651
##  6 NEAR EAST        23.4  10456.  79.5 209.  25.0   4.81 0.0638 0.406 0.53 
##  7 NORTHERN AFRICA  30.9   5460   67.2 100.  20.8   4.81 0.135  0.426 0.432
##  8 NORTHERN AMERICA  8.63 26100   97.8 687.  13.2   7.69 0.014  0.199 0.787
##  9 OCEANIA          20.2   8248.  88.8 190.  22.1   5.81 0.175  0.215 0.609
## 10 SUB-SAHARAN AFR… 80.0   2324.  62.5  42.5 36.0  15.2  0.284  0.267 0.450
## 11 WESTERN EUROPE    4.73 27046.  98.4 594.  10.6   9.35 0.0445 0.246 0.715
```

---
# Cluster hierárquico


```r
dist(dataset %&gt;% slice(1:5) %&gt;% select(-X0))  # cálculos das distâncias (5 objetos)
```

```
##           1         2         3         4
## 2 3248.9717                              
## 3 4053.6265 7301.2357                    
## 4 1758.5439 1491.7275 5809.6013          
## 5  637.1044 2617.9324 4683.5352 1126.2310
```

```r
(fitHC &lt;- hclust(dist(dataset %&gt;% select(-X0)))) # ajuste do cluster
```

```
## 
## Call:
## hclust(d = dist(dataset %&gt;% select(-X0)))
## 
## Cluster method   : complete 
## Distance         : euclidean 
## Number of objects: 11
```

---
# Dendograma

.pull-left[

```r
fitHC$labels &lt;- dataset$X0

fitHC %&gt;% plot(cex = .7)
```
]

.pull-right[
&lt;img src="rladies-ml_files/figure-html/unnamed-chunk-28-1.png" width="504" style="display: block; margin: auto;" /&gt;
]

---
# Outros tipos de dendograma (e.g. `ape::as.phylo()`)


```r
fitHC %&gt;% ape::as.phylo() %&gt;% plot(type = "fan", cex = .7) # "unrooted"/"cladogram"
```

&lt;img src="rladies-ml_files/figure-html/unnamed-chunk-29-1.png" width="504" style="display: block; margin: auto;" /&gt;

---
# Padronização


```r
dataset_scaled &lt;- 
  dataset %&gt;% 
  mutate_at(vars(X1:X9), list(scale))

dataset_scaled
```

```
## # A tibble: 11 x 10
##    X0    X1[,1]  X2[,1] X3[,1]   X4[,1]  X5[,1] X6[,1] X7[,1]  X8[,1]
##    &lt;chr&gt;  &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;
##  1 ASIA…  0.679 -0.367  -0.581 -0.515    0.315  -0.300  0.717  0.0954
##  2 BALT… -0.849  0.0315  0.938  0.101   -1.19    1.21  -0.917 -0.0279
##  3 C.W.…  0.799 -0.864   0.862 -0.552   -0.105   0.519  0.894  0.457 
##  4 EAST… -0.641 -0.152   0.739  0.0394  -1.06    0.502 -0.336  0.195 
##  5 LATI… -0.305 -0.290   0.255 -0.00656  0.0506 -0.682 -0.350 -0.549 
##  6 NEAR… -0.156 -0.0721 -0.584 -0.323    0.808  -1.16  -0.685  1.55  
##  7 NORT…  0.186 -0.685  -1.51  -0.874    0.271  -1.16   0.192  1.83  
##  8 NORT… -0.826  1.85    0.789  2.09    -0.703  -0.283 -1.30  -1.34  
##  9 OCEA… -0.300 -0.343   0.118 -0.420    0.436  -0.853  0.686 -1.12  
## 10 SUB-…  2.42  -1.07   -1.86  -1.17     2.21    1.98   2.02  -0.398 
## 11 WEST… -1.00   1.96    0.837  1.62    -1.03    0.220 -0.924 -0.689 
## # … with 1 more variable: X9[,1] &lt;dbl&gt;
```

---
# Análise com dados padronizados

.pull-left[

```r
fitHCscaled &lt;- hclust(dist(dataset_scaled %&gt;% select(-X0)))

fitHCscaled$labels &lt;- dataset$X0

fitHCscaled %&gt;% plot(cex = .7)
```
]

.pull-right[
&lt;img src="rladies-ml_files/figure-html/unnamed-chunk-31-1.png" width="504" /&gt;

]
---
# Classificação

.pull-left[

Corte utilizando o argumento `k`:


```r
cutree(fitHCscaled, k = 3) %&gt;% reshape2::melt(value.name = "cluster")
```

```
##                      cluster
## ASIA (EX. NEAR EAST)       1
## BALTICS                    1
## C.W. OF IND. STATES        1
## EASTERN EUROPE             1
## LATIN AMER. &amp; CARIB        1
## NEAR EAST                  1
## NORTHERN AFRICA            1
## NORTHERN AMERICA           2
## OCEANIA                    1
## SUB-SAHARAN AFRICA         3
## WESTERN EUROPE             2
```
]

.pull-right[

Corte utilizando o argumento `h`:


```r
cutree(fitHCscaled, h = 4) %&gt;% reshape2::melt(value.name = "cluster")
```

```
##                      cluster
## ASIA (EX. NEAR EAST)       1
## BALTICS                    1
## C.W. OF IND. STATES        1
## EASTERN EUROPE             1
## LATIN AMER. &amp; CARIB        1
## NEAR EAST                  2
## NORTHERN AFRICA            2
## NORTHERN AMERICA           3
## OCEANIA                    1
## SUB-SAHARAN AFRICA         4
## WESTERN EUROPE             3
```
]

---
# K-means


```r
(fitKMscaled &lt;- kmeans(dataset_scaled %&gt;% select(-X0), 3))
```

```
## K-means clustering with 3 clusters of sizes 4, 2, 5
## 
## Cluster means:
##           X1         X2         X3          X4         X5          X6
## 1 -0.5240548 -0.1882576  0.5123305 -0.07166434 -0.4398122  0.04473033
## 2 -0.9141307  1.9059808  0.8129264  1.85803098 -0.8687811 -0.03129828
## 3  0.7848961 -0.6117862 -0.7350349 -0.68588092  0.6993622 -0.02326495
##           X7         X8         X9
## 1 -0.2293036 -0.3754964  0.3980571
## 2 -1.1114926 -1.0159858  1.4638807
## 3  0.6280399  0.7067914 -0.9039980
## 
## Clustering vector:
##  [1] 3 1 3 1 1 3 3 2 1 3 2
## 
## Within cluster sum of squares by cluster:
## [1]  8.3717169  0.8036231 27.8187741
##  (between_SS / total_SS =  58.9 %)
## 
## Available components:
## 
## [1] "cluster"      "centers"      "totss"        "withinss"    
## [5] "tot.withinss" "betweenss"    "size"         "iter"        
## [9] "ifault"
```

---
# Comparando modelos

.pull-left[

```r
dataset_scaled %&gt;% 
  select(countries = X0) %&gt;% 
  mutate(cluster = fitKMscaled$cluster)
```

```
## # A tibble: 11 x 2
##    countries            cluster
##    &lt;chr&gt;                  &lt;int&gt;
##  1 ASIA (EX. NEAR EAST)       3
##  2 BALTICS                    1
##  3 C.W. OF IND. STATES        3
##  4 EASTERN EUROPE             1
##  5 LATIN AMER. &amp; CARIB        1
##  6 NEAR EAST                  3
##  7 NORTHERN AFRICA            3
##  8 NORTHERN AMERICA           2
##  9 OCEANIA                    1
## 10 SUB-SAHARAN AFRICA         3
## 11 WESTERN EUROPE             2
```
]

.pull-right[

```r
cutree(fitHCscaled, k = 3) %&gt;% reshape2::melt(value.name = "cluster")
```

```
##                      cluster
## ASIA (EX. NEAR EAST)       1
## BALTICS                    1
## C.W. OF IND. STATES        1
## EASTERN EUROPE             1
## LATIN AMER. &amp; CARIB        1
## NEAR EAST                  1
## NORTHERN AFRICA            1
## NORTHERN AMERICA           2
## OCEANIA                    1
## SUB-SAHARAN AFRICA         3
## WESTERN EUROPE             2
```
]

---
# Classificando subdistribuições

.pull-left[

```r
set.seed(1256)

distrib1 &lt;- rnorm(70, mean = 3, sd = 1)
distrib2 &lt;- rnorm(60, mean = 6, sd = 2)

distrib &lt;- c(distrib1, distrib2)

ggplot() +
  geom_histogram(aes(x = distrib), fill = "black") +
  theme_minimal() +
  labs(x = "x")
```
]

.pull-right[
&lt;img src="rladies-ml_files/figure-html/unnamed-chunk-37-1.png" width="504" /&gt;
]

---
# Aplicando K-means


```r
(fitKM &lt;- kmeans(distrib, 2))
```

```
## K-means clustering with 2 clusters of sizes 44, 86
## 
## Cluster means:
##       [,1]
## 1 6.595374
## 2 3.048047
## 
## Clustering vector:
##   [1] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
##  [36] 2 2 2 1 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2
##  [71] 1 1 2 2 1 1 1 1 1 1 1 1 1 1 2 1 2 2 1 2 1 1 2 2 1 1 1 1 2 1 2 1 2 1 1
## [106] 2 1 1 1 1 2 1 1 1 1 2 2 1 1 1 1 1 2 1 1 1 1 2 2 2
## 
## Within cluster sum of squares by cluster:
## [1] 81.37757 85.58016
##  (between_SS / total_SS =  68.7 %)
## 
## Available components:
## 
## [1] "cluster"      "centers"      "totss"        "withinss"    
## [5] "tot.withinss" "betweenss"    "size"         "iter"        
## [9] "ifault"
```

---
# Classificações

.pull-left[

```r
distrib %&gt;% 
  tibble(x = .) %&gt;% 
  mutate(cluster = fitKM$cluster %&gt;% as.factor) %&gt;% 
  ggplot(aes(x = x, fill = cluster, group = cluster)) +
  geom_histogram(alpha = .5) +
  theme_minimal()
```
]

.pull-right[
&lt;img src="rladies-ml_files/figure-html/unnamed-chunk-39-1.png" width="504" /&gt;
]

---
# Validação do número de clusters


```r
require(clValid)

results &lt;-
  dataset_scaled %&gt;% select(-X0) %&gt;% as.matrix() %&gt;% 
  clValid(., 
          2:5, # número de clusters
          clMethods = c("hierarchical", "kmeans"), # métodos
          validation = c("internal","stability")) # medidas

res &lt;-getRanksWeights(results)
print(res$ranks[ ,1:3], quote = FALSE)
```

```
##              1              2              3             
## APN          hierarchical-2 kmeans-5       hierarchical-5
## AD           kmeans-5       hierarchical-5 hierarchical-4
## ADM          hierarchical-2 kmeans-5       hierarchical-5
## FOM          kmeans-5       hierarchical-5 hierarchical-4
## Connectivity hierarchical-2 kmeans-2       hierarchical-3
## Dunn         hierarchical-5 kmeans-5       hierarchical-4
## Silhouette   hierarchical-2 kmeans-2       hierarchical-5
```

---
class: left middle
background-color: yellow

# Colocando modelos em produção

.large[Utilização de API]

---
# Plumber

.pull-left[

An R package that converts your existing R code to a web API using a handful of special one-line comments. 

]

.pull-right[

![](resources/images/plumber-broken.png)

]
---
# Plumber


```r
require(plumber)

#* @apiTitle Prediction Survived

#* Return the prediction survived
#* @param sex Sex
#* @param pclass Pclass
#* @param age Age
#* @get /predict
function(sex, pclass, age) {
  
  load("R/plumber.RData")
  
  predict(cart0, newdata = data.frame(Sex = sex, Pclass = pclass, Age = as.numeric(age)))[2]
  
}
```


```r
plumber::plumb("R/predict.R")$run(port = 8000)
```

---
class: center middle

&lt;img src="resources/images/citation.jpeg" width="427" height="60%" /&gt;
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"ratio": "16:9",
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false,
"slideNumberFormat": "<div class=\"progress-bar-container\">   <div class=\"progress-bar\" style=\"width: calc(%current% / %total% * 100%);\">   </div> </div>"
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
